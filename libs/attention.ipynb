{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daeb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import re\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae269ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0005  # Learning rate for the model training process\n",
    "vec_len = 50  # Length of the vector for the attention model\n",
    "seq_len = 20  # Length of the input sequence for the attention model\n",
    "num_epochs = 50  # Number of training epochs\n",
    "\n",
    "label_col = \"Product\"  # Name of the column containing product labels in the dataset\n",
    "\n",
    "# Paths to various data files and saved models\n",
    "tokens_path = \"Output/tokens.pkl\"  # Path to save tokens\n",
    "labels_path = \"Output/labels.pkl\"  # Path to save labels\n",
    "data_path = \"Input/complaints.csv\"  # Path to the input dataset (CSV file)\n",
    "model_path = \"Output/attention.pth\"  # Path to save the trained attention model\n",
    "vocabulary_path = \"Output/vocabulary.pkl\"  # Path to save vocabulary\n",
    "embeddings_path = \"Output/embeddings.pkl\"  # Path to save word embeddings\n",
    "glove_vector_path = \"Input/glove.6B.50d.txt\"  # Path to the GloVe word vectors file\n",
    "text_col_name = \"Consumer complaint narrative\"  # Name of the text column in the dataset\n",
    "\n",
    "label_encoder_path = \"Output/label_encoder.pkl\"  # Path to save the label encoder\n",
    "\n",
    "# A dictionary mapping product names to shorter names or labels\n",
    "product_map = {\n",
    "    'Vehicle loan or lease': 'vehicle_loan',\n",
    "    'Credit reporting, credit repair services, or other personal consumer reports': 'credit_report',\n",
    "    'Credit card or prepaid card': 'card',\n",
    "    'Money transfer, virtual currency, or money service': 'money_transfer',\n",
    "    'virtual currency': 'money_transfer',\n",
    "    'Mortgage': 'mortgage',\n",
    "    'Payday loan, title loan, or personal loan': 'loan',\n",
    "    'Debt collection': 'debt_collection',\n",
    "    'Checking or savings account': 'savings_account',\n",
    "    'Credit card': 'card',\n",
    "    'Bank account or service': 'savings_account',\n",
    "    'Credit reporting': 'credit_report',\n",
    "    'Prepaid card': 'card',\n",
    "    'Payday loan': 'loan',\n",
    "    'Other financial service': 'others',\n",
    "    'Virtual currency': 'money_transfer',\n",
    "    'Student loan': 'loan',\n",
    "    'Consumer Loan': 'loan',\n",
    "    'Money transfers': 'money_transfer'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce10573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(name, obj):\n",
    "    \"\"\"\n",
    "    Function to save an object as pickle file\n",
    "    \"\"\"\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "\n",
    "def load_file(name):\n",
    "    \"\"\"\n",
    "    Function to load a pickle object\n",
    "    \"\"\"\n",
    "    return pickle.load(open(name, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1217b362",
   "metadata": {},
   "source": [
    "## Process glove embeddings\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa79027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the GloVe word vectors file at 'glove_vector_path'\n",
    "with open(glove_vector_path, \"rt\") as f:\n",
    "    emb = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f7c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store vocabulary and embeddings\n",
    "vocabulary, embeddings = [], []\n",
    "\n",
    "# Iterate through each item in the 'emb' list\n",
    "for item in emb:\n",
    "    # Split the item into a list of words using space as the delimiter\n",
    "    # The first element [0] is considered as the word in the vocabulary\n",
    "    word = item.split()[0]\n",
    "\n",
    "    # The remaining elements [1:] are considered as the embedding values\n",
    "    embedding = item.split()[1:]\n",
    "\n",
    "    # Append the word to the 'vocabulary' list\n",
    "    vocabulary.append(word)\n",
    "\n",
    "    # Append the embedding values to the 'embeddings' list\n",
    "    embeddings.append(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e2ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'embeddings' list to a NumPy array\n",
    "embeddings = np.array(embeddings, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18ab05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the special tokens\n",
    "special_tokens = [\"<pad>\", \"<unk>\"]\n",
    "\n",
    "# Concatenate the special tokens with the existing 'vocabulary' list\n",
    "vocabulary = special_tokens + vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a row of ones\n",
    "ones_row = np.ones(50, dtype=np.float32)\n",
    "\n",
    "# Compute the mean of 'embeddings'\n",
    "mean_embedding = np.mean(embeddings, axis=0)\n",
    "\n",
    "# Stack ones, mean, and original embeddings vertically\n",
    "combined_embeddings = np.vstack([ones_row, mean_embedding, embeddings])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a10ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the 'embeddings' data\n",
    "save_file(embeddings_path, embeddings)\n",
    "\n",
    "# Save the 'vocabulary' data\n",
    "save_file(vocabulary_path, vocabulary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df5b4ed",
   "metadata": {},
   "source": [
    "## Process text data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0857024",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a1d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=[text_col_name], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf860ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in the 'label_col' column of the 'data' DataFrame\n",
    "# using the mapping defined in 'product_map'\n",
    "data.replace({label_col: product_map}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86a2b5c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2046a04",
   "metadata": {},
   "source": [
    "### Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the 'label_col' values in the data\n",
    "label_encoder.fit(data[label_col])\n",
    "\n",
    "# Transform 'label_col' values into numerical labels\n",
    "labels = label_encoder.transform(data[label_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90f15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(labels_path, labels)\n",
    "save_file(label_encoder_path, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36758aeb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b68c08",
   "metadata": {},
   "source": [
    "### Process the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251a804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of input text from the 'text_col_name' column in the 'data' DataFrame\n",
    "input_text = list(data[text_col_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccee9aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee49234f",
   "metadata": {},
   "source": [
    "### Convert text to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf262880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each element in 'input_text' to lowercase using list comprehension\n",
    "# while displaying a tqdm progress bar\n",
    "input_text = [i.lower() for i in tqdm(input_text)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceef1b67",
   "metadata": {},
   "source": [
    "### Remove punctuations except apostrophe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c3e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace non-alphanumeric characters (excluding single quotes and spaces) \n",
    "# with a space in each element of 'input_text' while displaying a tqdm progress bar\n",
    "input_text = [re.sub(r\"[^\\w\\d'\\s]+\", \" \", i) for i in tqdm(input_text)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78914b0f",
   "metadata": {},
   "source": [
    "### Remove digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed47512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all digits from each element of 'input_text' while displaying a tqdm progress bar\n",
    "input_text = [re.sub(\"\\d+\", \"\", i) for i in tqdm(input_text)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24176de",
   "metadata": {},
   "source": [
    "### Remove more than one consecutive instance of 'x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a31a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove consecutive occurrences of 'x' (two or more) from each element of 'input_text'\n",
    "input_text = [re.sub(r'[x]{2,}', \"\", i) for i in tqdm(input_text)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb9005a",
   "metadata": {},
   "source": [
    "### Remove multiple spaces with single space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ae0965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace multiple consecutive spaces with a single space in each element of 'input_text'\n",
    "input_text = [re.sub(' +', ' ', i) for i in tqdm(input_text)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d2eb78",
   "metadata": {},
   "source": [
    "### Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3393da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize each element of 'input_text' into words while displaying a tqdm progress bar\n",
    "tokens = [word_tokenize(t) for t in tqdm(input_text)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f29b1b2",
   "metadata": {},
   "source": [
    "### Take the first 20 tokens in each complaint text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c7eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that each tokenized element in 'tokens' has a maximum length of 20 words\n",
    "# by padding with '<pad>' if needed, while displaying a tqdm progress bar\n",
    "tokens = [i[:20] if len(i) > 19 else ['<pad>'] * (20 - len(i)) + i for i in tqdm(tokens)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f520434",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec18f209",
   "metadata": {},
   "source": [
    "### Convert tokens to integer indices from vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd525d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_index(tokens, vocabulary, missing='<unk>'):\n",
    "    \"\"\"\n",
    "    Convert a list of word tokens to a list of corresponding integers based on a given vocabulary.\n",
    "\n",
    "    :param tokens: List of word tokens to be converted.\n",
    "    :param vocabulary: List of all words in the embeddings.\n",
    "    :param missing: Token to use for words not present in the vocabulary (default is '<unk>').\n",
    "    \n",
    "    :return: List of integers representing the word tokens.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an empty list to store the integer representations of tokens\n",
    "    idx_token = []\n",
    "    \n",
    "    # Iterate through each text in 'tokens'\n",
    "    for text in tqdm(tokens):\n",
    "        # Initialize an empty list to store the integer representations of words in the text\n",
    "        idx_text = []\n",
    "        # Iterate through each token in the text\n",
    "        for token in text:\n",
    "            # Check if the token is in the vocabulary\n",
    "            if token in vocabulary:\n",
    "                # Append the index of the token in the vocabulary to idx_text\n",
    "                idx_text.append(vocabulary.index(token))\n",
    "            else:\n",
    "                # Append the index of the 'missing' token to idx_text if token is not in the vocabulary\n",
    "                idx_text.append(vocabulary.index(missing))\n",
    "        # Append the list of integer representations of words in the text to idx_token\n",
    "        idx_token.append(idx_text)\n",
    "    \n",
    "    # Return the list of integer representations of word tokens\n",
    "    return idx_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = token_index(tokens, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e48e10a",
   "metadata": {},
   "source": [
    "### Save the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23952d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(tokens_path, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3515fc26",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b005f51",
   "metadata": {},
   "source": [
    "## Create attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d15041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A neural network model that applies attention mechanism to input data.\n",
    "\n",
    "    :param vec_len: Length of input vectors.\n",
    "    :param seq_len: Length of input sequences.\n",
    "    :param n_classes: Number of output classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vec_len, seq_len, n_classes):\n",
    "        super(AttentionModel, self).__init__()\n",
    "\n",
    "        # Define the length of input vectors and sequences\n",
    "        self.vec_len = vec_len\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # Initialize attention weights with random values\n",
    "        self.attn_weights = torch.cat([torch.tensor([[0.]]),\n",
    "                                       torch.randn(vec_len, 1) /\n",
    "                                       torch.sqrt(torch.tensor(vec_len))])\n",
    "        self.attn_weights.requires_grad = True\n",
    "        self.attn_weights = nn.Parameter(self.attn_weights)\n",
    "\n",
    "        # Activation function for attention\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        # Softmax function to compute attention weights\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        # Linear layer for the final output\n",
    "        self.linear = nn.Linear(vec_len + 1, n_classes)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        \"\"\"\n",
    "        Forward pass of the attention model.\n",
    "\n",
    "        :param input_data: Input data (shape: batch_size x seq_len x vec_len).\n",
    "\n",
    "        :return: Model output (shape: batch_size x n_classes).\n",
    "        \"\"\"\n",
    "\n",
    "        # Calculate weighted hidden states using attention weights\n",
    "        hidden = torch.matmul(input_data, self.attn_weights)\n",
    "        hidden = self.activation(hidden)\n",
    "\n",
    "        # Compute attention weights using softmax\n",
    "        attn = self.softmax(hidden)\n",
    "\n",
    "        # Repeat and reshape attention weights for element-wise multiplication\n",
    "        attn = attn.repeat(1, 1, self.vec_len + 1).reshape(attn.shape[0],\n",
    "                                                           self.seq_len,\n",
    "                                                           self.vec_len + 1)\n",
    "\n",
    "        # Apply attention to the input data\n",
    "        attn_output = input_data * attn\n",
    "\n",
    "        # Sum along the sequence dimension\n",
    "        attn_output = torch.sum(attn_output, axis=1)\n",
    "\n",
    "        # Pass the attention-weighted output through a linear layer\n",
    "        output = self.linear(attn_output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f515b0",
   "metadata": {},
   "source": [
    "## Create PyTorch dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch dataset for text classification tasks.\n",
    "\n",
    "    :param tokens: List of word tokens.\n",
    "    :param embeddings: Word embeddings (e.g., from GloVe).\n",
    "    :param labels: List of labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokens, embeddings, labels):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with the provided data.\n",
    "\n",
    "        :param tokens: List of word tokens.\n",
    "        :param embeddings: Word embeddings (from GloVe or similar).\n",
    "        :param labels: List of labels.\n",
    "        \"\"\"\n",
    "        self.tokens = tokens\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the total number of samples in the dataset.\n",
    "\n",
    "        :return: The number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a single sample from the dataset by index.\n",
    "\n",
    "        :param idx: Index of the sample to retrieve.\n",
    "\n",
    "        :return: A tuple containing label and input data.\n",
    "        \"\"\"\n",
    "        emb = torch.tensor(self.embeddings[self.tokens[idx], :])\n",
    "\n",
    "        # Concatenate a column of ones to the embeddings\n",
    "        input_ = torch.cat((torch.ones(emb.shape[0], 1), emb), dim=1)\n",
    "\n",
    "        return torch.tensor(self.labels[idx]), input_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fa32d5",
   "metadata": {},
   "source": [
    "### Function to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d51e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, valid_loader, model, criterion, optimizer, \n",
    "          device, num_epochs, model_path):\n",
    "    \"\"\"\n",
    "    Train a deep learning model.\n",
    "\n",
    "    :param train_loader: Data loader for the training dataset.\n",
    "    :param valid_loader: Data loader for the validation dataset.\n",
    "    :param model: The neural network model to be trained.\n",
    "    :param criterion: Loss function to compute training and validation loss.\n",
    "    :param optimizer: Optimizer for updating model parameters.\n",
    "    :param device: Device for training (e.g., CUDA or CPU).\n",
    "    :param num_epochs: Number of training epochs.\n",
    "    :param model_path: Path to save the trained model.\n",
    "    \"\"\"\n",
    "    best_loss = 1e8\n",
    "\n",
    "    # Loop over the specified number of training epochs\n",
    "    for i in range(num_epochs):\n",
    "        print(f\"Epoch {i+1} of {num_epochs}\")\n",
    "        valid_loss, train_loss = [], []\n",
    "\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "\n",
    "        # Training loop\n",
    "        for batch_labels, batch_data in tqdm(train_loader):\n",
    "            # Move data to the specified device (e.g., GPU)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            batch_data = batch_data.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            batch_output = model(batch_data)\n",
    "            batch_output = torch.squeeze(batch_output)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(batch_output, batch_labels)\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backward pass and gradient update\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Set the model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Validation loop\n",
    "        for batch_labels, batch_data in tqdm(valid_loader):\n",
    "            # Move data to the specified device (e.g., GPU)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            batch_data = batch_data.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            batch_output = model(batch_data)\n",
    "            batch_output = torch.squeeze(batch_output)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(batch_output, batch_labels)\n",
    "            valid_loss.append(loss.item())\n",
    "\n",
    "        # Compute and print average training and validation loss\n",
    "        t_loss = np.mean(train_loss)\n",
    "        v_loss = np.mean(valid_loss)\n",
    "        print(f\"Train Loss: {t_loss}, Validation Loss: {v_loss}\")\n",
    "\n",
    "        if v_loss < best_loss:\n",
    "            best_loss = v_loss\n",
    "\n",
    "            # Save the model if validation loss improves\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        print(f\"Best Validation Loss: {best_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7227423",
   "metadata": {},
   "source": [
    "### Function to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c4e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, criterion, device):\n",
    "    \"\"\"\n",
    "    Test a trained deep learning model on a test dataset.\n",
    "\n",
    "    :param test_loader: Data loader for the test dataset.\n",
    "    :param model: The trained neural network model to be tested.\n",
    "    :param criterion: Loss function to compute test loss.\n",
    "    :param device: Device for testing (e.g., CUDA or CPU).\n",
    "    \"\"\"\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize lists to store test loss and accuracy\n",
    "    test_loss = []\n",
    "    test_accu = []\n",
    "\n",
    "    # Iterate over the test dataset\n",
    "    for batch_labels, batch_data in tqdm(test_loader):\n",
    "        # Move data to the specified device (e.g., GPU)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        batch_data = batch_data.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        batch_output = model(batch_data)\n",
    "        batch_output = torch.squeeze(batch_output)\n",
    "\n",
    "        # Calculate loss and store it\n",
    "        loss = criterion(batch_output, batch_labels)\n",
    "        test_loss.append(loss.item())\n",
    "\n",
    "        # Calculate batch predictions\n",
    "        batch_preds = torch.argmax(batch_output, axis=1)\n",
    "\n",
    "        # Move predictions and labels to CPU if using CUDA\n",
    "        if torch.cuda.is_available():\n",
    "            batch_labels = batch_labels.cpu()\n",
    "            batch_preds = batch_preds.cpu()\n",
    "\n",
    "        # Compute accuracy for the batch and store it\n",
    "        test_accu.append(accuracy_score(batch_labels.detach().numpy(), batch_preds.detach().numpy()))\n",
    "\n",
    "    # Compute and print the average test loss and accuracy\n",
    "    test_loss = np.mean(test_loss)\n",
    "    test_accu = np.mean(test_accu)\n",
    "    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accu}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90695c4c",
   "metadata": {},
   "source": [
    "## Train attention model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a18d4c",
   "metadata": {},
   "source": [
    "### Load the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78d0cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load token data from 'tokens_path'\n",
    "tokens = load_file(tokens_path)\n",
    "\n",
    "# Load label data from 'labels_path'\n",
    "labels = load_file(labels_path)\n",
    "\n",
    "# Load word embeddings from 'embeddings_path'\n",
    "embeddings = load_file(embeddings_path)\n",
    "\n",
    "# Load label encoder from 'label_encoder_path'\n",
    "label_encoder = load_file(label_encoder_path)\n",
    "\n",
    "# Determine the number of classes based on the label encoder\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Load vocabulary data from 'vocabulary_path'\n",
    "vocabulary = load_file(vocabulary_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37271b2",
   "metadata": {},
   "source": [
    "### Split data into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12905bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets, reserving 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(tokens, labels, test_size=0.2)\n",
    "\n",
    "# Further split the training data into training and validation sets, reserving 25% for validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca11ca1",
   "metadata": {},
   "source": [
    "### Create PyTorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e17e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset using 'X_train' data, 'embeddings', and 'y_train' labels\n",
    "train_dataset = TextDataset(X_train, embeddings, y_train)\n",
    "\n",
    "# Create validation dataset using 'X_valid' data, 'embeddings', and 'y_valid' labels\n",
    "valid_dataset = TextDataset(X_valid, embeddings, y_valid)\n",
    "\n",
    "# Create test dataset using 'X_test' data, 'embeddings', and 'y_test' labels\n",
    "test_dataset = TextDataset(X_test, embeddings, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e699aa78",
   "metadata": {},
   "source": [
    "### Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4726f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training data loader with a batch size of 16, shuffling the data, and dropping the last incomplete batch\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "\n",
    "# Create a validation data loader with a batch size of 16\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16)\n",
    "\n",
    "# Create a test data loader with a batch size of 16\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d484ef",
   "metadata": {},
   "source": [
    "### Create model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8cffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the computing device to use for training (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddc6d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the 'AttentionModel' with specified parameters\n",
    "model = AttentionModel(vec_len, seq_len, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540a7d38",
   "metadata": {},
   "source": [
    "### Move the model to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942190dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a GPU (CUDA) is available, and if so, move the model to the GPU\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1850d25e",
   "metadata": {},
   "source": [
    "### Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss criterion for classification tasks (CrossEntropyLoss)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer for model parameter updates (Adam optimizer with a specified learning rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a405ca0",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de992e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the deep learning model using the specified data loaders, model, loss criterion,\n",
    "# optimizer, device, number of epochs, and save the best model to 'model_path'\n",
    "train(train_loader, valid_loader, model, criterion, optimizer, device, num_epochs, model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3520d07b",
   "metadata": {},
   "source": [
    "### Test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d9d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained deep learning model on the test dataset using the specified data loader,\n",
    "# model, loss criterion, and device for testing\n",
    "test(test_loader, model, criterion, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb74fa",
   "metadata": {},
   "source": [
    "## Predict on new text\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b65a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = '''I am a victim of Identity Theft & currently have an Experian account that \n",
    "I can view my Experian Credit Report and getting notified when there is activity on \n",
    "my Experian Credit Report. For the past 3 days I've spent a total of approximately 9 \n",
    "hours on the phone with Experian. Every time I call I get transferred repeatedly and \n",
    "then my last transfer and automated message states to press 1 and leave a message and \n",
    "someone would call me. Every time I press 1 I get an automatic message stating than you \n",
    "before I even leave a message and get disconnected. I call Experian again, explain what \n",
    "is happening and the process begins again with the same end result. I was trying to have \n",
    "this issue attended and resolved informally but I give up after 9 hours. There are hard \n",
    "hit inquiries on my Experian Credit Report that are fraud, I didn't authorize, or recall \n",
    "and I respectfully request that Experian remove the hard hit inquiries immediately just \n",
    "like they've done in the past when I was able to speak to a live Experian representative \n",
    "in the United States. The following are the hard hit inquiries : BK OF XXXX XX/XX/XXXX \n",
    "XXXX XXXX XXXX  XX/XX/XXXX XXXX  XXXX XXXX  XX/XX/XXXX XXXX  XX/XX/XXXX XXXX  XXXX \n",
    "XX/XX/XXXX'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449d0cc6",
   "metadata": {},
   "source": [
    "### Process input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d73be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert input text to lowercase\n",
    "input_text = input_text.lower()\n",
    "\n",
    "# Replace non-alphanumeric characters (excluding single quotes and spaces) with spaces\n",
    "input_text = re.sub(r\"[^\\w\\d'\\s]+\", \" \", input_text)\n",
    "\n",
    "# Remove all digits from the text\n",
    "input_text = re.sub(\"\\d+\", \"\", input_text)\n",
    "\n",
    "# Remove consecutive occurrences of 'x' (two or more) from the text\n",
    "input_text = re.sub(r'[x]{2,}', \"\", input_text)\n",
    "\n",
    "# Replace multiple consecutive spaces with a single space\n",
    "input_text = re.sub(' +', ' ', input_text)\n",
    "\n",
    "# Tokenize the preprocessed input text\n",
    "tokens = word_tokenize(input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f97ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the 'tokens' list has a maximum length of 20 by padding with '<pad>' if needed\n",
    "tokens = ['<pad>'] * (20 - len(tokens)) + tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'tokens' into a list of integers by looking up each token in the 'vocabulary'\n",
    "# If a token is not found in the vocabulary, use the index of '<unk>' as a fallback\n",
    "idx_token = []\n",
    "for token in tokens:\n",
    "    if token in vocabulary:\n",
    "        idx_token.append(vocabulary.index(token))\n",
    "    else:\n",
    "        idx_token.append(vocabulary.index('<unk>'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d4275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve word embeddings for the 'idx_token' indices from the 'embeddings' matrix\n",
    "token_emb = embeddings[idx_token, :]\n",
    "\n",
    "# Limit the embeddings to the first 'seq_len' elements, if needed\n",
    "token_emb = token_emb[:seq_len, :]\n",
    "\n",
    "# Convert the 'token_emb' NumPy array to a PyTorch tensor\n",
    "inp = torch.from_numpy(token_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adfdbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate a column of ones to the 'inp' tensor along the second dimension (column-wise)\n",
    "inp = torch.cat((torch.ones(inp.shape[0], 1), inp), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76afacda",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() \n",
    "                      else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b78e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the 'inp' tensor to the specified device (e.g., GPU)\n",
    "inp = inp.to(device)\n",
    "\n",
    "# Add an extra dimension at the beginning of the tensor (batch dimension)\n",
    "inp = torch.unsqueeze(inp, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7152087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the label encoder from the specified file path\n",
    "label_encoder = load_file(label_encoder_path)\n",
    "\n",
    "# Determine the number of classes based on the label encoder\n",
    "num_classes = len(label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ea657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the 'AttentionModel' with specified parameters\n",
    "model = AttentionModel(vec_len, seq_len, num_classes)\n",
    "\n",
    "# Load the trained model weights from the specified 'model_path'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Move the model to the GPU if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "# Perform a forward pass of the model to obtain the output\n",
    "out = torch.squeeze(model(inp))\n",
    "\n",
    "# Find the predicted class by selecting the class with the highest output probability\n",
    "prediction = label_encoder.classes_[torch.argmax(out)]\n",
    "\n",
    "# Print the predicted class\n",
    "print(f\"Predicted Class: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea861ff",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7392fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
